{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90255f88-34dd-418b-ad94-8fd3f5e985fe",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa5b69-8a7d-420c-88cb-894efc966324",
   "metadata": {},
   "source": [
    "## Libraries etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6505d4e4-9c3a-4f96-bbe1-840b5b5c42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "from qanda import QandA\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247525cd-409d-424d-aa2c-622c6f18729c",
   "metadata": {},
   "source": [
    "## Run the Preprocessor\n",
    "Do you have some new data? If you have a new document, place it in the `data/` directory and then run the `preprocessor.py` module. The document will be processed with OCR and the result will be placed in the `jsondata/` directory.\n",
    "\n",
    "Let's say your new file is `Rodier-finding.pdf` and you've put it in the `data/` directory with all your other documents. Now you just need to invoke `preprocessor.py`. Heres how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9b42ed-3922-4397-bd35-0f5aa04ef086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: a message saying 'Token indices sequence length is longer than the specified maximum sequence length...' can be ignored in this case\n",
      "Details: https://github.com/docling-project/docling-core/issues/119#issuecomment-2577418826\n",
      "\n",
      "Processing Rodier-Finding.pdf\n",
      "Document Rodier-Finding.pdf converted in 30.88 seconds.\n",
      "jsondata/Blood-results-redacted.jsonl already exists.\n",
      "jsondata/Nicholls-Diver-finding.jsonl already exists.\n",
      "jsondata/TAULELEI-Jacob-Finding.jsonl already exists.\n",
      "jsondata/Forkin-finding-2014.jsonl already exists.\n",
      "jsondata/Baby-H-finding.jsonl already exists.\n",
      "\n",
      "Finished.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run preprocessor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d68176a-54c1-4966-9671-ac54a70dd203",
   "metadata": {},
   "source": [
    "**NB** If you don't need to use OCR on your document you can just go in and set `ocr=False` in the `batch_convert` function of the `preprocessor.py` module.\n",
    "\n",
    "Now let's take a look in the `jsondata/` directory where we'll see our new document is ready to be loaded into a vector store, i.e., it's been converted into a pre-chunked and serialized JSONL object file with metadata attached - `Rodier-Finding.jsonl`. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43e9b499-d605-40b0-9dd1-b809b4677e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TAULELEI-Jacob-Finding.jsonl',\n",
       " 'Rodier-Finding.jsonl',\n",
       " 'Blood-results-redacted.jsonl',\n",
       " 'Forkin-finding-2014.jsonl',\n",
       " 'Baby-H-finding.jsonl',\n",
       " 'Nicholls-Diver-finding.jsonl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('jsondata/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad6282-8c83-49b0-8a71-eabe515f1a33",
   "metadata": {},
   "source": [
    "## Initialize a QandA Object\n",
    "No we've got our document ready let's start up a RAG question answer chain. To do so we'll need to initialise a `QandA` object which is just a Python object that encapsulates all the things we need. Those things are:\n",
    "\n",
    "- `FILE_PATH`: the file path to the pre-processed docuement you want to analyse (i.e., `jsondata/Rodier-Finding.jsonl`)\n",
    "- `GEN_MODEL`: which generative LLM model you want to use (i.e., from Ollama)\n",
    "- `EMBED_MODEL`: the vector embedding model (i.e., `mxbai-embed-large`)\n",
    "- `VDB`: the actual vector store (i.e., `InMemoryVectorStore`)\n",
    "- `TOP_K`: how many sources of context to use for the vector similarity search\n",
    "- `PROMP`: the prompt template\n",
    "\n",
    "OK, let's intitialise the `QandA` object now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db43b47-f11f-419e-a90a-173125d3b130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing, please wait...\n",
      "Loading jsondata/Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n"
     ]
    }
   ],
   "source": [
    "# Set the file (document); generative LLM model; embedding model;\n",
    "# vec db; num sources\n",
    "FILE_PATH = Path(\"jsondata/Rodier-Finding.jsonl\")\n",
    "GEN_MODEL = \"gemma3\"\n",
    "EMBED_MODEL = \"mxbai-embed-large\"\n",
    "VDB = InMemoryVectorStore\n",
    "TOP_K = 3\n",
    "\n",
    "# Set the prompt\n",
    "PROMPT = ChatPromptTemplate.from_template(\n",
    "    \"\"\"Context information is below.\n",
    "    \\n---------------------\\n\n",
    "    {context}\n",
    "    \\n---------------------\\n\n",
    "    Given the context information and not prior knowledge, answer the query.\\n\n",
    "    Query: {input}\\n\n",
    "    Answer:\\n\"\"\",\n",
    ")\n",
    "\n",
    "# Initialize the qanda object\n",
    "qanda = QandA(gen_model=GEN_MODEL,\n",
    "              embed_model=EMBED_MODEL, \n",
    "              vdb=VDB,\n",
    "              file_path=FILE_PATH,\n",
    "              top_k=TOP_K,\n",
    "              prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a5cf13-a69b-484f-b783-872516abb6dc",
   "metadata": {},
   "source": [
    "Take a look at the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cec1ff9-b46c-4027-8849-c3b651f68e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on QandA in module qanda object:\n",
      "\n",
      "class QandA(builtins.object)\n",
      " |  QandA(gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |\n",
      " |  A class for performing question-answering tasks using a language model and a vector database.\n",
      " |\n",
      " |  Attributes:\n",
      " |      gen_model (str): The name of the language model to be used for generating answers.\n",
      " |      embed_model (str): The name of the embedding model to be used for generating embeddings.\n",
      " |      vdb (str): The name of the vector database to be used for storing and retrieving documents.\n",
      " |      file_path (str): The path to the file containing the documents to be used for the question-answering task.\n",
      " |      top_k (int): The number of top-k most relevant documents to be retrieved for each question.\n",
      " |      prompt (str): The prompt to be used for the question-answering chain.\n",
      " |\n",
      " |  Methods:\n",
      " |      ask(question, verbose=False):\n",
      " |          Invokes the question-answering chain to generate an answer to the given question.\n",
      " |          Args:\n",
      " |              question (str): The question to be answered.\n",
      " |              verbose (bool, optional): If True, the method will return the answer and the sources used to generate the answer. Defaults to False.\n",
      " |          Returns:\n",
      " |              str or (str, list): The answer to the question, or a tuple containing the answer and the sources used to generate the answer.\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, gen_model, embed_model, vdb, file_path, top_k, prompt)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  ask(self, question, verbose=False)\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Qanda help\n",
    "help(qanda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf3da6-0dee-45b4-b5ed-255396fba807",
   "metadata": {},
   "source": [
    "## Several Methods to use a QandA Object\n",
    "There are number of ways to use the `qanda` object you've created to extract and analyse info from your document. Let's go through some now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1937bdc-7cd9-43c0-b498-9888f36ce271",
   "metadata": {},
   "source": [
    "## Method 1: Just answer the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aacf1ce3-e1f8-4127-85b7-142bd7ad955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank Edward Rodier died.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask some questions\n",
    "qanda.ask(\"Who died?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4969d29-48c9-45cc-a8d5-883fd574b42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fishing.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qanda.ask(\"Acitvity involved in death?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4721f99b-c21d-479c-84cf-edc8ca718d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank Rodier, Donald McLeod, and Ducas went fishing.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qanda.ask(\"Who went fishing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69386664-8a35-469d-9eec-b27849b82c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  Sarah Helen Linton, Deputy State Coroner.\n",
      "Answer 2:  Frank Edward Rodier is the deceased.\n",
      "Answer 3:  The cause of death remains unascertained. The report states, “Accordingly, his cause of death must remain unascertained.”\n"
     ]
    }
   ],
   "source": [
    "# Create a list of questions\n",
    "QUESTIONS = [\"Who is the coroner?\",\n",
    "             \"Who is the deceased?\",\n",
    "             \"What was the cause of death?\"]\n",
    "\n",
    "# Get the answers\n",
    "for i, QUESTION in enumerate(QUESTIONS):\n",
    "    ANSWER = qanda.ask(QUESTION)\n",
    "    print(f\"Answer {i + 1}: \", ANSWER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864400a3-2801-4508-9859-f7a1b730055d",
   "metadata": {},
   "source": [
    "## Method 2: Answer the questions and score the answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca3a2d2e-76f1-4dc4-a371-4a5b05ba154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a scores function with the BERTScore metric\n",
    "def calculate_bertscore_df(df):\n",
    "    references = df['CORRECT_ANSWER'].tolist()\n",
    "    candidates = df['LLM_ANSWER'].tolist()\n",
    "    \n",
    "    precision, recall, f1 = score(candidates, references, lang=\"en\", verbose=True)\n",
    "    \n",
    "    df['BERT_PRECISION'] = precision.tolist()\n",
    "    df['BERT_RECALL'] = recall.tolist()\n",
    "    df['BERT_F1'] = f1.tolist()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1e7ecd-a8ad-46a8-b753-e1b38ae57a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the questions... and the correct answers\n",
    "QUESTIONS = [\"Who is the coroner?\",\n",
    "             \"Who is the deceased?\",\n",
    "             \"What was the cause of death?\"]\n",
    "CORRECT_ANSWERS = [\"Sarah Helen Linton\",\n",
    "                   \"Frank Edward Rodier\",\n",
    "                   \"unascertained\"]\n",
    "LLM_ANSWERS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a1b41b2-f68b-4205-b88d-b232f0cfc4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  Sarah Helen Linton, Deputy State Coroner.\n",
      "Answer 2:  Frank Edward Rodier is the deceased.\n",
      "Answer 3:  The cause of death remains unascertained. The coroner determined that while it was likely an accident, the death was caused by injuries sustained from the rocks, and the specific cause could not be determined.\n"
     ]
    }
   ],
   "source": [
    "# get the answers from the RAG chain, i.e., the LLM_ANSWERS\n",
    "for i, QUESTION in enumerate(QUESTIONS):\n",
    "    ANSWER = qanda.ask(QUESTION)\n",
    "    LLM_ANSWERS.append(ANSWER)\n",
    "    print(f\"Answer {i + 1}: \", ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de10cb52-4499-4765-a8d5-798116a04dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe\n",
    "data = {\n",
    "    'FILENAME': ['Rodier-Finding'] * len(QUESTIONS),\n",
    "    'MODEL': ['gemma3'] * len(QUESTIONS),\n",
    "    'QUESTION': QUESTIONS,\n",
    "    'CORRECT_ANSWER': CORRECT_ANSWERS,\n",
    "    'LLM_ANSWER': LLM_ANSWERS\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df8143e0-2206-4292-97b3-83ec92424fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae852cb6bb74345b8f24a43e7c6be0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b853d0e2a71e4fb3bd8d6774136f2be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.60 seconds, 1.88 sentences/sec\n",
      "Index(['FILENAME', 'MODEL', 'QUESTION', 'CORRECT_ANSWER', 'LLM_ANSWER',\n",
      "       'BERT_PRECISION', 'BERT_RECALL', 'BERT_F1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# score the answers\n",
    "scores_df = calculate_bertscore_df(df)\n",
    "\n",
    "print(scores_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa40e37-ff78-4f46-a631-268ab722dfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FILENAME   MODEL                      QUESTION       CORRECT_ANSWER  \\\n",
      "0  Rodier-Finding  gemma3           Who is the coroner?   Sarah Helen Linton   \n",
      "1  Rodier-Finding  gemma3          Who is the deceased?  Frank Edward Rodier   \n",
      "2  Rodier-Finding  gemma3  What was the cause of death?        unascertained   \n",
      "\n",
      "                                          LLM_ANSWER  BERT_PRECISION  \\\n",
      "0          Sarah Helen Linton, Deputy State Coroner.        0.888055   \n",
      "1               Frank Edward Rodier is the deceased.        0.913599   \n",
      "2  The cause of death remains unascertained. The ...        0.805766   \n",
      "\n",
      "   BERT_RECALL   BERT_F1  \n",
      "0     0.959326  0.922316  \n",
      "1     0.961740  0.937052  \n",
      "2     0.863840  0.833793  \n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432f3f9-c963-4097-8f45-db40d4fcc25a",
   "metadata": {},
   "source": [
    "## Method 3: Answer the question and provide the source context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd192cad-9755-4b11-b3b3-8e8a73ad7069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose a question, get the answer... and sources\n",
    "QUESTION = \"What activity was implicated in the cause of death?\"\n",
    "ANSWER, SOURCES = qanda.ask(QUESTION, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8c50dc9-c947-4121-b56d-e72d6d711001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fishing.\n"
     ]
    }
   ],
   "source": [
    "print(ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4428774-902c-4e0e-9f96-6e4a85bb0bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': 1, 'text': 'IS DEATH ESTABLISHED?\\n17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks while fishing with friends. May\\n18. but I cannot exclude the possibility that he died from injuries he sustained from the rocks, or that injury at least contributed to his death. Accordingly, his cause of death must remain unascertained. As to the manner of death, I am satisfied he died by way of accident.', 'page': 6, 'document': 'data/Rodier-Finding.pdf'}, {'source': 2, 'text': 'INTRODUCTION\\n- 2 In my capacity as the Acting State Coroner, I determined on the basis of information provided by the WA Police in August 2023 that   there was   reasonable cause to suspect that Frank had died and that his death was a reportable death under the Act. I therefore made a direction to the Commissioner of Police; pursuant to s 23(1) of the Coroners Act 1996 (WA) that the suspected death be investigated.', 'page': 3, 'document': 'data/Rodier-Finding.pdf'}, {'source': 3, 'text': '[2024] WACOR 35\\nimpediment; associated with events at the time of his birth. He had no known medical conditions that would have shortened his life span: 3', 'page': 4, 'document': 'data/Rodier-Finding.pdf'}]\n"
     ]
    }
   ],
   "source": [
    "print(SOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec0fb22c-50ac-4a53-90e8-368e88ca1613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IS DEATH ESTABLISHED?\n",
      "17. As is clear from the above; I am satisfied beyond reasonable doubt that Frank Rodier is deceased and that he died on 25 1975 in the sea after he was washed off the rocks while fishing with friends. May\n",
      "18. but I cannot exclude the possibility that he died from injuries he sustained from the rocks, or that injury at least contributed to his death. Accordingly, his cause of death must remain unascertained. As to the manner of death, I am satisfied he died by way of accident.\n"
     ]
    }
   ],
   "source": [
    "print(SOURCES[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7084b8da-eac5-4d0c-a472-32c459a8c0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(SOURCES[0]['page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c1f33e8-fad3-4e64-9d84-2eede09cd011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Rodier-Finding.pdf\n"
     ]
    }
   ],
   "source": [
    "print(SOURCES[0]['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f06e03c-e79b-46cf-bea0-06741b2a1892",
   "metadata": {},
   "source": [
    "##  Method 4: Compare answers of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98a656e-f09e-454d-8079-0d0eac5a29ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the models\n",
    "LLAMA = \"llama3.2\"\n",
    "GEMMA = \"gemma3\"\n",
    "PHI   = \"phi4-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a5fc77e-767e-472d-ae35-9ee7e99647b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing, please wait...\n",
      "Loading jsondata/Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n",
      "Initializing, please wait...\n",
      "Loading jsondata/Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n",
      "Initializing, please wait...\n",
      "Loading jsondata/Rodier-Finding.jsonl\n",
      "Question Answer chain ready.\n"
     ]
    }
   ],
   "source": [
    "# initialise RAG chains (i.e., QandA objects) for each model\n",
    "qanda_llama = QandA(gen_model=LLAMA,\n",
    "                    embed_model=EMBED_MODEL, \n",
    "                    vdb=VDB,\n",
    "                    file_path=FILE_PATH,\n",
    "                    top_k=TOP_K,\n",
    "                    prompt=PROMPT)\n",
    "\n",
    "qanda_gemma = QandA(gen_model=GEMMA,\n",
    "                    embed_model=EMBED_MODEL, \n",
    "                    vdb=VDB,\n",
    "                    file_path=FILE_PATH,\n",
    "                    top_k=TOP_K,\n",
    "                    prompt=PROMPT)\n",
    "\n",
    "qanda_phi = QandA(gen_model=PHI,\n",
    "                  embed_model=EMBED_MODEL, \n",
    "                  vdb=VDB,\n",
    "                  file_path=FILE_PATH,\n",
    "                  top_k=TOP_K,\n",
    "                  prompt=PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3055e186-dd06-431a-8216-8ec55fbf84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose a question (which you know the answer to)\n",
    "QUESTION = \"What activity was implicated in the cause of death?\"\n",
    "CORRECT_ANSWER = \"Fishing\"\n",
    "LLM_ANSWERS = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17557b85-396b-437c-b81d-d0f581a37bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1:  Based on the provided context, it can be inferred that fishing with friends is the activity implicated in the cause of death. This is because Frank Rodier was washed off the rocks while fishing with friends, which led to his subsequent drowning or accidental death.\n",
      "Answer 2:  Fishing.\n",
      "Answer 3:  Based on the provided context:\n",
      "\n",
      "The specific circumstances surrounding Frank Rodier's drowning are described as occurring while he \"was washed off the rocks\" during an outing that involved fishing with friends. It is mentioned at one point, however, there might also have been a possibility for injuries from these rocky surfaces to contribute or exacerbate his demise.\n",
      "\n",
      "Therefore:\n",
      "Answer: Fishing on the sea with rock hazards implied in cause of death (accidental drowning potentially linked to both falling into water and possible injury)\n"
     ]
    }
   ],
   "source": [
    "# get the generated answer for each model RAG chain\n",
    "for i, qanda_model in enumerate([qanda_llama, qanda_gemma, qanda_phi]):\n",
    "    ANSWER = qanda_model.ask(QUESTION)\n",
    "    LLM_ANSWERS.append(ANSWER)\n",
    "    print(f\"Answer {i + 1}: \", ANSWER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f7dbb2b-3c4f-479a-9698-bb5f8a4eb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe\n",
    "data = {\n",
    "    'FILENAME': ['Rodier-Finding'] * 3,\n",
    "    'MODEL': [LLAMA, GEMMA, PHI],\n",
    "    'QUESTION': [QUESTION] * 3,\n",
    "    'CORRECT_ANSWER': [CORRECT_ANSWER] * 3,\n",
    "    'LLM_ANSWER': LLM_ANSWERS\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b33ee0c-2de2-4953-ad9a-58120b7c9e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc74850a2984aa58f73429bea2b4cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e1e75c3605483d9d54069bcee52f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.26 seconds, 2.39 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "# score the answers\n",
    "scores_df = calculate_bertscore_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9bb713d-5ef5-42b1-accc-477e71362090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FILENAME', 'MODEL', 'QUESTION', 'CORRECT_ANSWER', 'LLM_ANSWER',\n",
      "       'BERT_PRECISION', 'BERT_RECALL', 'BERT_F1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(scores_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd700da6-fd2e-4e90-8732-11a7efde9ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         FILENAME      MODEL  \\\n",
      "0  Rodier-Finding   llama3.2   \n",
      "1  Rodier-Finding     gemma3   \n",
      "2  Rodier-Finding  phi4-mini   \n",
      "\n",
      "                                            QUESTION CORRECT_ANSWER  \\\n",
      "0  What activity was implicated in the cause of d...        Fishing   \n",
      "1  What activity was implicated in the cause of d...        Fishing   \n",
      "2  What activity was implicated in the cause of d...        Fishing   \n",
      "\n",
      "                                          LLM_ANSWER  BERT_PRECISION  \\\n",
      "0  Based on the provided context, it can be infer...        0.793064   \n",
      "1                                           Fishing.        0.968601   \n",
      "2  Based on the provided context:\\n\\nThe specific...        0.770629   \n",
      "\n",
      "   BERT_RECALL   BERT_F1  \n",
      "0     0.819261  0.805950  \n",
      "1     0.937267  0.952677  \n",
      "2     0.828657  0.798590  \n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1768591c-c3b5-46a8-943f-37fa7d8dbc4a",
   "metadata": {},
   "source": [
    "**_That's it!_**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
